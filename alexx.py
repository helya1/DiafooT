import streamlit as st
import pandas as pd
import numpy as np
from scipy.stats import shapiro, probplot, ttest_rel, wilcoxon, friedmanchisquare # Added friedmanchisquare
import matplotlib.pyplot as plt
import io
from statsmodels.formula.api import ols # Not directly used in the provided snippets but often useful with AnovaRM
from statsmodels.stats.anova import AnovaRM # Added AnovaRM

st.set_page_config(layout="wide")
st.title("üìã Analyse Myoton")

# Consolidated sidebar radio button for page navigation
page = st.sidebar.radio(
    "Choisir la page :",
    [
        "Statistiques par zone",
        "Test de normalit√©",
        "Comparaison Gauche vs Droit (Q-Q Plot & Boxplot)", # Renamed for clarity
        "Plot Planck-Hartmann (Individuel)", # Renamed for clarity
        "Plot Planck-Hartmann (Moyenne R√©p√©titions)", # Renamed for clarity
        "Test de sym√©trie Gauche/Droite", # Renamed for clarity and consolidated
        "Test inter-zone (param√©trique/non-param√©trique)", # Renamed for clarity
        "Compare Inter-Zone (Detailed)" # Renamed for clarity
    ]
)

uploaded_file = st.file_uploader("üìÇ Charger le fichier Excel", type=["xlsx"])

if uploaded_file:
    sheet_name = "Manips resultats"
    df = pd.read_excel(uploaded_file, sheet_name=sheet_name, header=None)
    index_map = {
        'tone_right':      [i-1 for i in [3,4,5,23,24,25,43,44,45,63,64,65,83,84,85,103,104,105,123,124,125,143,144,145,163,164,165]],
        'tone_left':       [i-1 for i in [13,14,15,33,34,35,53,54,55,73,74,75,93,94,95,113,114,115,133,134,135,153,154,161,173,174,175]],
        'stiffness_right': [i-1 for i in [6,7,8,26,27,28,46,47,48,66,67,68,86,87,88,106,107,108,126,127,128,146,147,148,166,167,168]],
        'stiffness_left':  [i-1 for i in [16,17,18,36,37,38,56,57,58,76,77,78,96,97,98,116,117,118,136,137,138,156,157,158,176,177,178]],
        'frequency_right': [i-1 for i in [9,10,11,29,30,31,49,50,51,69,70,71,89,90,91,109,110,111,129,130,131,149,150,151,169,170,171]],
        'frequency_left':  [i-1 for i in [19,20,21,39,40,41,59,60,61,79,80,81,99,100,101,119,120,121,139,140,141,159,160,161,179,180,181]]
    }

    foot_zones = ['Hallux', '1T', '2-3T', '5T', 'Voute int', 'Voute ext', 'Talon']

    # This 'parameters' list is used for iterating through parameters for display/analysis
    parameters_display_keys = [
        ("Tone - Pied Droit",      'tone_right'),
        ("Tone - Pied Gauche",     'tone_left'),
        ("Stiffness - Pied Droit", 'stiffness_right'),
        ("Stiffness - Pied Gauche",'stiffness_left'),
        ("Frequency - Pied Droit", 'frequency_right'),
        ("Frequency - Pied Gauche",'frequency_left')
    ]

    # This list is used for right/left comparison tests
    parameters_comparison_keys = [
        ("Tone", "tone_right", "tone_left"),
        ("Stiffness", "stiffness_right", "stiffness_left"),
        ("Frequency", "frequency_right", "frequency_left")
    ]

    def extract_param(index_list):
        # Ensure the extracted data is properly converted to numeric, handling potential non-numeric entries
        extracted_df = df.iloc[index_list].reset_index(drop=True).T
        # Select only the first 7 columns as per original logic, assuming they correspond to foot_zones
        return extracted_df.iloc[:, :7].apply(pd.to_numeric, errors='coerce')


    if page == "Statistiques par zone":
        st.header("üìä Statistiques par zone")
        def compute_statistics_by_zone(data, param_name):
            stats = []
            for i, zone in enumerate(foot_zones):
                values = pd.to_numeric(data.iloc[:, i], errors='coerce').dropna() # Ensure values are numeric and drop NaNs for stats
                mean = values.mean()
                std = values.std()
                cv = std / mean if mean != 0 else np.nan

                if pd.isna(cv):
                    interpretation = "Donn√©es insuffisantes ou CV ind√©fini"
                elif cv < 0.10:
                    interpretation = "‚úÖ Bonne repr√©sentativit√© (CV < 10%)"
                elif cv < 0.20:
                    interpretation = "‚ö†Ô∏è Variabilit√© mod√©r√©e (10% ‚â§ CV < 20%)"
                else:
                    interpretation = "‚ùå Forte variabilit√© (CV ‚â• 20%)"

                stats.append({
                    "Zone": zone,
                    "Moyenne": f"{mean:.2f}" if pd.notnull(mean) else "N/A",
                    "√âcart-type": f"{std:.2f}" if pd.notnull(std) else "N/A",
                    "CV (%)": f"{cv * 100:.2f}" if pd.notnull(cv) else "N/A",
                    "Interpr√©tation": interpretation
                })
            return pd.DataFrame(stats)

        for label, key in parameters_display_keys:
            st.markdown(f"### üìå {label}")
            data = extract_param(index_map[key])
            stats_df = compute_statistics_by_zone(data, label)
            st.dataframe(stats_df)

            st.markdown("‚ÑπÔ∏è **Interpr√©tation des CV :**")
            st.markdown("- ‚úÖ **CV < 10%** : faible variabilit√©, la moyenne est repr√©sentative")
            st.markdown("- ‚ö†Ô∏è **CV entre 10% et 20%** : variabilit√© mod√©r√©e, interpr√©tation avec prudence")
            st.markdown("- ‚ùå **CV > 20%** : forte variabilit√©, la moyenne est peu fiable")


    # --- Partie 2 : Test de normalit√© de Shapiro-Wilk ---
    elif page == "Test de normalit√©":
        st.header("üß™ Normalit√© par zone, param√®tre et c√¥t√© :(Shapiro-Wilk)")

        st.markdown("""
        **Objectif :** V√©rifier si les donn√©es suivent une distribution normale dans chaque zone.
        """)

        def test_normality_only(data, param_name, foot_zones):
            results = []
            for i, zone in enumerate(foot_zones):
                values = pd.to_numeric(data.iloc[:, i], errors='coerce').dropna()

                if len(values) >= 3:
                    stat, p_value = shapiro(values)
                else:
                    stat, p_value = np.nan, np.nan

                results.append({
                    "Zone": zone,
                    "p-value": f"{p_value:.4f}" if pd.notna(p_value) else "N/A",
                    "Conclusion": "‚úÖ Normale" if pd.notna(p_value) and p_value > 0.05 else "‚ùå Non normale"
                })

            result_df = pd.DataFrame(results)
            st.write(f"üìã R√©sultats du test de Shapiro-Wilk pour : {param_name}")
            st.dataframe(result_df)

        # Affichage normalit√© simple for all parameters (right and left)
        for label, key in parameters_display_keys:
            st.markdown(f"### üîç {label}")
            data = extract_param(index_map[key])
            test_normality_only(data, label, foot_zones)

        st.markdown("""
        ### üß† Interpr√©tation
        Ce tableau affiche la normalit√© **pour chaque combinaison : zone du pied √ó param√®tre √ó c√¥t√©**.

        - ‚úÖ signifie que les donn√©es suivent une distribution normale (*tests param√©triques possibles*)
        - ‚ùå signifie que les donn√©es ne sont pas normales (*tests non param√©triques recommand√©s*)

        Le **test de Shapiro-Wilk** permet de v√©rifier si les donn√©es suivent une **loi normale**.
        - Si la *p-value > 0.05*, on consid√®re que les donn√©es sont **normalement distribu√©es** (*test param√©trique possible* : t-test, ANOVA).
        - Si la *p-value ‚â§ 0.05*, les donn√©es **ne suivent pas une loi normale** (*test non param√©trique recommand√©* : Wilcoxon, Friedman).
        """)

    elif page == "Comparaison Gauche vs Droit (Q-Q Plot & Boxplot)": # Updated page name
        st.header("üìä Comparaison Gauche vs Droit ‚Äì par Param√®tre et Zone")

        def plot_combined_zonewise_boxplot(param_key_right, param_key_left, param_name, foot_zones, df_excel, index_map):
            data_right = extract_param(index_map[param_key_right])
            data_left = extract_param(index_map[param_key_left])

            box_data = []
            positions = []
            labels = []
            width = 0.35  # Half-width for side-by-side boxplots

            zone_indexes = range(len(foot_zones))

            fig, ax = plt.subplots(figsize=(12, 6))
            for i, zone in enumerate(foot_zones):
                vals_right = pd.to_numeric(data_right.iloc[:, i], errors='coerce').dropna()
                vals_left = pd.to_numeric(data_left.iloc[:, i], errors='coerce').dropna()

                if len(vals_right) < 2 or len(vals_left) < 2:
                    st.warning(f"Pas assez de donn√©es pour la zone '{zone}' ({param_name}) ‚Äì ignor√©e.")
                    continue

                # Pied droit
                bp1 = ax.boxplot(vals_right, positions=[i - width/2], widths=width,
                                patch_artist=True, boxprops=dict(facecolor='lightblue'), showfliers=False)
                # Pied gauche
                bp2 = ax.boxplot(vals_left, positions=[i + width/2], widths=width,
                                patch_artist=True, boxprops=dict(facecolor='lightgreen'), showfliers=False)

                labels.append(zone)

            ax.set_xticks(list(zone_indexes))
            ax.set_xticklabels(foot_zones, rotation=20)
            ax.set_title(f"üì¶ Comparaison Pied Droit vs Gauche ‚Äì {param_name}")
            ax.set_ylabel(param_name)
            ax.grid(True)
            ax.legend([bp1["boxes"][0], bp2["boxes"][0]], ["Pied Droit", "Pied Gauche"], loc="upper right")
            st.pyplot(fig)
            plt.close(fig)
            

        def plot_all_zones_comparison(param_key_right, param_key_left, param_name, foot_zones, df_excel, index_map):
            data_right = extract_param(index_map[param_key_right])
            data_left = extract_param(index_map[param_key_left])

            # Flatten all zone values into one array per side
            vals_right_all = []
            vals_left_all = []

            for i in range(len(foot_zones)):
                vals_right_zone = pd.to_numeric(data_right.iloc[:, i], errors='coerce').dropna().tolist()
                vals_left_zone = pd.to_numeric(data_left.iloc[:, i], errors='coerce').dropna().tolist()

                vals_right_all.extend(vals_right_zone)
                vals_left_all.extend(vals_left_zone)

            if len(vals_right_all) < 2 or len(vals_left_all) < 2:
                st.warning(f"Pas assez de donn√©es globales pour tracer '{param_name}'.")
                return

            # Boxplot global
            fig, ax = plt.subplots(figsize=(6, 4))
            ax.boxplot([vals_right_all, vals_left_all], patch_artist=True,
                    labels=["Pied Droit", "Pied Gauche"],
                    boxprops=dict(facecolor="lightblue"),
                    medianprops=dict(color='black'))

            ax.set_title(f"üì¶ Boxplot global ‚Äì {param_name} (toutes zones)")
            ax.grid(True)
            st.pyplot(fig)
            plt.close(fig)


        for param_name, key_right, key_left in parameters_comparison_keys:
            st.subheader(f"üîπ {param_name}")
            plot_combined_zonewise_boxplot(key_right, key_left, param_name, foot_zones, df, index_map)


        for param_name, key_right, key_left in parameters_comparison_keys:
            st.subheader(f"üîπ {param_name}")
            plot_all_zones_comparison(key_right, key_left, param_name, foot_zones, df, index_map)
            

    elif page == "Plot Planck-Hartmann (Individuel)": # Updated page name
        st.header("üé≠ Planck-Hartmann - Comparaison Pied Droit / Pied Gauche (Individuel)")

        def plot_planck_hartmann(right_df_raw, left_df_raw, param_name, foot_zones):
            # Ensure data is numeric
            right_numeric = right_df_raw.apply(pd.to_numeric, errors='coerce')
            left_numeric = left_df_raw.apply(pd.to_numeric, errors='coerce')

            # Drop rows (subjects) that have any NaN values across all zones
            # This is important for consistent centering across subjects/zones
            right_numeric_clean = right_numeric.dropna()
            left_numeric_clean = left_numeric.dropna()

            if right_numeric_clean.empty or left_numeric_clean.empty:
                st.warning(f"Pas assez de donn√©es compl√®tes pour tracer le graphique Planck-Hartmann pour {param_name}.")
                return

            mean_right_zones = right_numeric_clean.mean(axis=0)
            mean_left_zones = left_numeric_clean.mean(axis=0)

            # Center individual data points by subtracting the *overall mean of that specific zone*
            centered_right = right_numeric_clean - mean_right_zones
            centered_left = left_numeric_clean - mean_left_zones


            # Moyenne globale (droite + gauche) - this mean should also be across zones
            mean_global = pd.concat([right_numeric_clean, left_numeric_clean]).mean(axis=0) # Mean of each zone across all subjects, both sides
            mean_global_centered = mean_global - mean_global.mean() # Center this global mean itself

            fig, ax = plt.subplots(figsize=(14, 6))
            x = np.arange(len(foot_zones))
            width = 0.15 # Reduced width for clarity in plots

            # Tracer chaque individu (droite)
            for i in range(len(centered_right)):
                # Adjust x-position for right side points slightly to the left of the zone center
                ax.plot(x - width, centered_right.iloc[i], marker='o', linestyle='-',
                        color='dodgerblue', alpha=0.6, label="Individu Pied Droit" if i == 0 else "")

            # Tracer chaque individu (gauche)
            for i in range(len(centered_left)):
                # Adjust x-position for left side points slightly to the right of the zone center
                ax.plot(x + width, centered_left.iloc[i], marker='o', linestyle='--',
                        color='darkorange', alpha=0.6, label="Individu Pied Gauche" if i == 0 else "")

            # Tracer la moyenne g√©n√©rale (droite + gauche) centr√©e (ligne √©paisse et couleur distincte)
            ax.plot(x, mean_global_centered, marker='s', linestyle='-', color='green', linewidth=3, label="Moyenne G√©n√©rale Centr√©e", alpha=0.8)

            # Ligne horizontale 0
            ax.axhline(0, color='red', linestyle='--', label="√âcart √† la moyenne = 0")

            ax.set_xticks(x)
            ax.set_xticklabels(foot_zones, fontsize=12)
            ax.set_ylabel("Valeur centr√©e (diff√©rence √† la moyenne globale de la zone)")
            ax.set_title(f"Graphique de Planck-Hartmann pour {param_name.upper()}")
            ax.legend(loc='upper right')
            ax.grid(True)

            # --- Partie t√©l√©chargement ---
            buf = io.BytesIO()
            fig.savefig(buf, format="png", bbox_inches='tight')
            buf.seek(0)
            st.download_button(
                label="üì• T√©l√©charger le graphique (PNG)",
                data=buf,
                file_name=f"Planck_Hartmann_Individuel_{param_name}.png",
                mime="image/png"
            )
            st.pyplot(fig)
            plt.close(fig) # Close plot to free memory

            # Calculate CI based on clean data
            if not right_numeric_clean.empty:
                ci_right = 1.96 * right_numeric_clean.stack().std() / np.sqrt(len(right_numeric_clean.stack().dropna()))
                st.info(f"Intervalle de confiance 95% estim√© pour le Pied Droit (globalement) : ¬±{ci_right:.2f}")
            if not left_numeric_clean.empty:
                ci_left = 1.96 * left_numeric_clean.stack().std() / np.sqrt(len(left_numeric_clean.stack().dropna()))
                st.info(f"Intervalle de confiance 95% estim√© pour le Pied Gauche (globalement) : ¬±{ci_left:.2f}")

        # Use actual extracted data, not simulated data
        for param_name, key_right, key_left in parameters_comparison_keys:
            st.subheader(f"üîπ {param_name}")
            data_right = extract_param(index_map[key_right])
            data_left = extract_param(index_map[key_left])
            plot_planck_hartmann(data_right, data_left, param_name, foot_zones)


        # --- Interpr√©tation du Plot Planck-Hartmann ---
        st.markdown("### üß† Interpr√©tation des graphiques Planck-Hartmann")
        st.markdown("""
        - **Les courbes bleues** repr√©sentent les valeurs centr√©es pour chaque individu au pied droit,
        tandis que les **courbes orange** repr√©sentent celles pour le pied gauche.
        - Les valeurs sont centr√©es par zone, c‚Äôest-√†-dire que l‚Äôon montre l‚Äô√©cart √† la moyenne **de chaque zone (tous sujets confondus)**,
        ce qui permet de visualiser les diff√©rences relatives de chaque sujet selon la zone du pied, par rapport √† la moyenne de cette zone.

        - La **courbe verte √©paisse** correspond √† la moyenne g√©n√©rale (droite + gauche) de tous les sujets **centr√©e par rapport √† sa propre moyenne**,
        permettant d‚Äô√©valuer la tendance moyenne globale pour chaque zone.

        - La **ligne rouge en pointill√©** indique la r√©f√©rence z√©ro (moyenne par zone).
        Des points au-dessus indiquent des valeurs sup√©rieures √† la moyenne,
        en dessous des valeurs inf√©rieures.

        - Les intervalles de confiance 95% (affich√©s en info) donnent une id√©e de la variabilit√© et de la pr√©cision de la moyenne.

        ### Comment interpr√©ter ?

        - Si les courbes individuelles (bleues et oranges) sont proches de la ligne rouge z√©ro et de la moyenne verte, cela signifie une homog√©n√©it√© des profils entre sujets et une faible variabilit√© autour de la moyenne de la zone.
        - De fortes variations individuelles peuvent indiquer une variabilit√© importante √† prendre en compte.
        - Des diff√©rences syst√©matiques entre pied droit et gauche (d√©calage entre les nuages de points bleus et oranges pour une m√™me zone) peuvent r√©v√©ler des asym√©tries biom√©caniques ou fonctionnelles.

        Cette visualisation permet ainsi d‚Äôidentifier facilement les zones du pied o√π la variabilit√© ou les asym√©tries sont les plus marqu√©es, et de guider des analyses ou interventions cibl√©es.
        """)

    elif page == "Plot Planck-Hartmann (Moyenne R√©p√©titions)": # Updated page name
        st.header("üìä Analyse avec moyenne des r√©p√©titions par zone, pied droit et pied gauche")

        def plot_planck_hartmann_mean_repetitions(right_df_raw, left_df_raw, param_name, foot_zones):
            st.markdown(f"### üé≠ Planck-Hartmann : {param_name.upper()}")

            right_numeric = right_df_raw.apply(pd.to_numeric, errors='coerce')
            left_numeric = left_df_raw.apply(pd.to_numeric, errors='coerce')

            # Drop rows (subjects) that have any NaN values across all zones
            right_numeric_clean = right_numeric.dropna()
            left_numeric_clean = left_numeric.dropna()

            if right_numeric_clean.empty or left_numeric_clean.empty:
                st.warning(f"Pas assez de donn√©es compl√®tes pour tracer le graphique Planck-Hartmann pour {param_name}.")
                return

            # Moyenne des r√©p√©titions par zone (axis=0 = colonne) - this calculates the mean across subjects for each zone
            mean_right_per_zone = right_numeric_clean.mean(axis=0)
            mean_left_per_zone = left_numeric_clean.mean(axis=0)

            # Centrer chaque r√©p√©tition (individu) par rapport √† la moyenne de sa ZONE (pas sa propre moyenne)
            # This is the core of a Planck-Hartmann plot: showing deviation from the overall zone mean
            centered_right = right_numeric_clean - mean_right_per_zone
            centered_left = left_numeric_clean - mean_left_per_zone

            # Moyenne globale (droite + gauche) across zones
            mean_global_across_zones = pd.concat([right_numeric_clean, left_numeric_clean]).mean(axis=0)
            mean_global_centered = mean_global_across_zones - mean_global_across_zones.mean() # Centered by its own mean

            fig, ax = plt.subplots(figsize=(14, 6))
            x = np.arange(len(foot_zones))
            width = 0.15

            # Tracer r√©p√©titions pied droit
            for i in range(len(centered_right)):
                ax.plot(x - width, centered_right.iloc[i], marker='o', linestyle='-',
                        color='dodgerblue', alpha=0.6, label="Individu Pied Droit" if i == 0 else "")

            # Tracer r√©p√©titions pied gauche
            for i in range(len(centered_left)):
                ax.plot(x + width, centered_left.iloc[i], marker='o', linestyle='--',
                        color='darkorange', alpha=0.6, label="Individu Pied Gauche" if i == 0 else "")

            # Tracer moyenne globale
            ax.plot(x, mean_global_centered, marker='s', linestyle='-', color='green', linewidth=3, label="Moyenne G√©n√©rale Centr√©e", alpha=0.8)

            ax.axhline(0, color='red', linestyle='--', label="√âcart √† la moyenne = 0")
            ax.set_xticks(x)
            ax.set_xticklabels(foot_zones)
            ax.set_ylabel("Valeur centr√©e (diff√©rence √† la moyenne globale de la zone)")
            ax.set_title(f"Graphique de Planck-Hartmann pour {param_name.upper()}")
            ax.legend(loc='upper right')
            ax.grid(True)

            # --- Partie t√©l√©chargement ---
            buf = io.BytesIO()
            fig.savefig(buf, format="png", bbox_inches='tight')
            buf.seek(0)
            st.download_button(
                label="üì• T√©l√©charger le graphique (PNG)",
                data=buf,
                file_name=f"Planck_Hartmann_Moyenne_Repetitions_{param_name}.png",
                mime="image/png"
            )
            st.pyplot(fig)
            plt.close(fig) # Close plot to free memory

            # Calculate CI based on clean data
            if not right_numeric_clean.empty:
                ci_right = 1.96 * right_numeric_clean.stack().std() / np.sqrt(len(right_numeric_clean.stack().dropna()))
                st.info(f"Intervalle de confiance 95% estim√© pour le Pied Droit (globalement) : ¬±{ci_right:.2f}")
            if not left_numeric_clean.empty:
                ci_left = 1.96 * left_numeric_clean.stack().std() / np.sqrt(len(left_numeric_clean.stack().dropna()))
                st.info(f"Intervalle de confiance 95% estim√© pour le Pied Gauche (globalement) : ¬±{ci_left:.2f}")

        # List of parameters to analyze and display
        for param_name, key_right, key_left in parameters_comparison_keys:
            st.markdown(f"## Analyse du param√®tre : {param_name}")
            data_right = extract_param(index_map[key_right])
            data_left = extract_param(index_map[key_left])
            plot_planck_hartmann_mean_repetitions(data_right, data_left, param_name, foot_zones)


    elif page == "Test de sym√©trie Gauche/Droite": # Consolidated and renamed page
        st.header("‚öñÔ∏è Test de sym√©trie Gauche vs Droit (t-test ou Wilcoxon selon normalit√©)")

        def test_symmetry_with_parametric_choice(param_key_right, param_key_left, foot_zones):
            data_right = extract_param(index_map[param_key_right])
            data_left = extract_param(index_map[param_key_left])

            results = []

            for i, zone in enumerate(foot_zones):
                vals_right = pd.to_numeric(data_right.iloc[:, i], errors='coerce').dropna()
                vals_left = pd.to_numeric(data_left.iloc[:, i], errors='coerce').dropna()

                # Find common indices for paired test
                common_idx = vals_right.index.intersection(vals_left.index)
                vals_right_paired = vals_right.loc[common_idx]
                vals_left_paired = vals_left.loc[common_idx]

                if len(vals_right_paired) < 2 or len(vals_left_paired) < 2: # Paired test needs at least 2 pairs
                    results.append({
                        "Zone": zone,
                        "Test utilis√©": "N/A",
                        "Statistique": "N/A",
                        "p-value": "N/A",
                        "Conclusion": "‚ö†Ô∏è Donn√©es insuffisantes pour test appari√©"
                    })
                    continue

                # Check normality with Shapiro-Wilk (min 3 data points for Shapiro-Wilk)
                norm_right = len(vals_right_paired) >= 3 and shapiro(vals_right_paired).pvalue > 0.05
                norm_left = len(vals_left_paired) >= 3 and shapiro(vals_left_paired).pvalue > 0.05

                # Choose test based on normality
                if norm_right and norm_left:
                    stat, p_value = ttest_rel(vals_right_paired, vals_left_paired)
                    test_used = "Test t appari√© (param√©trique)"
                else:
                    try:
                        stat, p_value = wilcoxon(vals_right_paired, vals_left_paired, zero_method='wilcox') # Added zero_method for consistency
                        test_used = "Test de Wilcoxon (non param√©trique)"
                    except ValueError as e:
                        stat, p_value = np.nan, np.nan
                        test_used = f"Test de Wilcoxon (erreur: {e})"

                # Interpretation of the result
                if pd.isna(p_value):
                    conclusion = "‚ö†Ô∏è Calcul impossible"
                elif p_value < 0.05:
                    conclusion = "‚ùå Diff√©rence significative"
                else:
                    conclusion = "‚úÖ Pas de diff√©rence significative"

                results.append({
                    "Zone": zone,
                    "Test utilis√©": test_used,
                    "Statistique": round(stat, 4) if not pd.isna(stat) else "N/A",
                    "p-value": round(p_value, 4) if not pd.isna(p_value) else "N/A",
                    "Conclusion": conclusion
                })

            return pd.DataFrame(results)

        for param_name, key_right, key_left in parameters_comparison_keys:
            st.subheader(f"üîπ {param_name}")
            df_results = test_symmetry_with_parametric_choice(key_right, key_left, foot_zones)
            st.dataframe(df_results)

        st.markdown("""
        **Interpr√©tation :**
        - Si **p-value < 0.05**, il existe une diff√©rence significative entre pied droit et gauche pour cette zone et param√®tre.
        - Si **p-value ‚â• 0.05**, pas de diff√©rence significative (sym√©trie).
        - Le test utilis√© est choisi selon la normalit√© des donn√©es (test de Shapiro-Wilk) :
        - Test t appari√© si donn√©es normales (param√©trique)
        - Test de Wilcoxon appari√© sinon (non param√©trique)
        """)


    elif page == "Test inter-zone (param√©trique/non-param√©trique)": # Consolidated and renamed page
        st.header("üß™ Comparaison inter-zones (ANOVA RM / Friedman)")

        # Simplified function for the main page display
        def test_inter_zone_summary(param_key, param_name, foot_zones):
            data = extract_param(index_map[param_key])
            # Ensure data is numeric and drop NaNs for analysis. Important for 'per subject' analysis later.
            data_num = data.apply(pd.to_numeric, errors='coerce').dropna()

            if data_num.empty:
                st.warning(f"Pas assez de donn√©es compl√®tes pour analyser {param_name}.")
                return

            # Test de normalit√© sur chaque zone
            normalities = []
            for col in data_num.columns: # Iterate over the actual columns of the cleaned data_num
                vals = data_num[col].dropna()
                if len(vals) >= 3:
                    p_val = shapiro(vals).pvalue
                else:
                    p_val = np.nan
                normalities.append(p_val)

            all_normal = all([(p > 0.05) for p in normalities if not pd.isna(p)])

            st.write(f"### R√©sultats pour : {param_name}")
            norm_df = pd.DataFrame({
                "Zone": foot_zones, # Use global foot_zones for display, assuming data_num columns map to it
                "p-value normalit√©": [f"{p:.4f}" if not pd.isna(p) else "N/A" for p in normalities],
                "Distribution": ["Normale" if (p > 0.05) else "Non normale" if not pd.isna(p) else "N/A" for p in normalities]
            })
            st.dataframe(norm_df)

            # Prepare data for ANOVA RM or Friedman: long format for AnovaRM, list of arrays for Friedman
            df_long = data_num.reset_index().melt(id_vars='index', value_vars=data_num.columns,
                                                     var_name='Zone', value_name='Valeur')
            df_long = df_long.rename(columns={'index': 'Sujet'})

            if all_normal:
                st.write("‚úÖ Toutes les zones consid√©r√©es comme normales. Effectue une ANOVA √† mesures r√©p√©t√©es.")
                try:
                    # Ensure 'Sujet' and 'Zone' are strings as AnovaRM expects
                    df_long['Sujet'] = df_long['Sujet'].astype(str)
                    df_long['Zone'] = df_long['Zone'].astype(str)
                    aovrm = AnovaRM(df_long, 'Valeur', 'Sujet', within=['Zone'])
                    res = aovrm.fit()
                    st.text(res.summary().as_text()) # Use as_text() for better display in Streamlit
                    p_val = res.anova_table["Pr > F"][0]

                    if p_val < 0.05:
                        st.success(f"Diff√©rence significative entre les zones (p = {p_val:.4f})")
                    else:
                        st.info(f"Aucune diff√©rence significative d√©tect√©e entre les zones (p = {p_val:.4f})")
                except Exception as e:
                    st.error(f"Erreur lors de l'ANOVA √† mesures r√©p√©t√©es : {e}")
                    st.warning("Assurez-vous que chaque sujet a des donn√©es pour toutes les zones pour l'ANOVA RM.")
            else:
                st.write("‚ùå Au moins une zone ne suit pas une distribution normale. Effectue un test de Friedman.")
                # Friedman takes *args, each arg is a data array for a group/zone
                vals_for_friedman = [data_num[col].dropna().values for col in data_num.columns]
                # Friedman requires at least 3 groups, and each group needs valid data
                if len(vals_for_friedman) < 3 or any(len(v) == 0 for v in vals_for_friedman):
                    st.warning("Pas assez de groupes ou de donn√©es valides par groupe pour le test de Friedman.")
                else:
                    try:
                        stat, p_val = friedmanchisquare(*vals_for_friedman)
                        st.write(f"Statistique Friedman : {stat:.4f}")
                        if p_val < 0.05:
                            st.success(f"Diff√©rence significative entre les zones (p = {p_val:.4f})")
                        else:
                            st.info(f"Aucune diff√©rence significative d√©tect√©e entre les zones (p = {p_val:.4f})")
                    except Exception as e:
                        st.error(f"Erreur lors du test de Friedman : {e}")
                        st.warning("V√©rifiez que toutes les zones ont des observations appari√©es (m√™me nombre de sujets avec des donn√©es compl√®tes pour toutes les zones).")

        # Loop through parameters (Tone, Stiffness, Frequency) for both right and left feet
        for param_name, key_right, key_left in parameters_comparison_keys: # Use comparison keys as they hold (param_name, right_key, left_key)
            st.markdown(f"## Analyse des zones pour {param_name}")
            st.subheader(f"Pied Droit - {param_name}")
            test_inter_zone_summary(key_right, f"{param_name} (Droit)", foot_zones) # Pass param_name with side
            st.subheader(f"Pied Gauche - {param_name}")
            test_inter_zone_summary(key_left, f"{param_name} (Gauche)", foot_zones) # Pass param_name with side


    
else:
    st.info("Veuillez charger un fichier Excel pour commencer l'analyse.")
