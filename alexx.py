import streamlit as st
import pandas as pd
import numpy as np
from scipy.stats import shapiro, probplot, ttest_rel, wilcoxon, friedmanchisquare # Added friedmanchisquare
import matplotlib.pyplot as plt
import io
from statsmodels.formula.api import ols # Not directly used in the provided snippets but often useful with AnovaRM
from statsmodels.stats.anova import AnovaRM # Added AnovaRM


st.set_page_config(layout="wide")
st.title("üìã Analyse Myoton")
page = st.sidebar.radio("Choisir la page :", ["Statistiques par zone", "Test de normalit√©", "plot_left_right_comparison", "plot planck_hartmann", "Moyenne r√©p√©titions", "test_symmetry_with_parametric_choice", "Test inter-zone (param√©trique/non-param√©trique)"])

uploaded_file = st.file_uploader("üìÇ Charger le fichier Excel", type=["xlsx"])

if uploaded_file:
    sheet_name = "Manips resultats"
    df = pd.read_excel(uploaded_file, sheet_name=sheet_name, header=None)
    index_map = {
        'tone_right':      [i-1 for i in [3,4,5,23,24,25,43,44,45,63,64,65,83,84,85,103,104,105,123,124,125,143,144,145,163,164,165]],
        'tone_left':       [i-1 for i in [13,14,15,33,34,35,53,54,55,73,74,75,93,94,95,113,114,115,133,134,135,153,154,161,173,174,175]],
        'stiffness_right': [i-1 for i in [6,7,8,26,27,28,46,47,48,66,67,68,86,87,88,106,107,108,126,127,128,146,147,148,166,167,168]],
        'stiffness_left':  [i-1 for i in [16,17,18,36,37,38,56,57,58,76,77,78,96,97,98,116,117,118,136,137,138,156,157,158,176,177,178]],
        'frequency_right': [i-1 for i in [9,10,11,29,30,31,49,50,51,69,70,71,89,90,91,109,110,111,129,130,131,149,150,151,169,170,171]],
        'frequency_left':  [i-1 for i in [19,20,21,39,40,41,59,60,61,79,80,81,99,100,101,119,120,121,139,140,141,159,160,161,179,180,181]]
    }

    foot_zones = ['Hallux', '1T', '2-3T', '5T', 'Voute int', 'Voute ext', 'Talon']

    parameters = [
        ("Tone - Pied Droit",      'tone_right'),
        ("Tone - Pied Gauche",     'tone_left'),
        ("Stiffness - Pied Droit", 'stiffness_right'),
        ("Stiffness - Pied Gauche",'stiffness_left'),
        ("Frequency - Pied Droit", 'frequency_right'),
        ("Frequency - Pied Gauche",'frequency_left')
    ]

    def extract_param(index_list):
        df_param = df.iloc[index_list].reset_index(drop=True).T.iloc[:, :7]
        df_param.columns = foot_zones  # üëà ici on renomme les colonnes
        return df_param


    if page == "Statistiques par zone":
        st.header("üìä Statistiques par zone")
        def compute_statistics_by_zone(data, param_name):
            stats = []
            for i, zone in enumerate(foot_zones):
                values = pd.to_numeric(data.iloc[:, i], errors='coerce')
                mean = values.mean()
                std = values.std()
                cv = std / mean if mean != 0 else np.nan

                if pd.isna(cv):
                    interpretation = "Donn√©es insuffisantes"
                elif cv < 0.10:
                    interpretation = "‚úÖ Bonne repr√©sentativit√© (CV < 10%)"
                elif cv < 0.20:
                    interpretation = "‚ö†Ô∏è Variabilit√© mod√©r√©e (10% ‚â§ CV < 20%)"
                else:
                    interpretation = "‚ùå Forte variabilit√© (CV ‚â• 20%)"

                stats.append({
                    "Zone": zone,
                    "Moyenne": mean,
                    "√âcart-type": std,
                    "CV (%)": f"{cv * 100:.2f}" if pd.notnull(cv) else "N/A",
                    "Interpr√©tation": interpretation
                })
            return pd.DataFrame(stats)

        parameters = [
            ("Tone - Pied Droit",      'tone_right'),
            ("Tone - Pied Gauche",     'tone_left'),
            ("Stiffness - Pied Droit", 'stiffness_right'),
            ("Stiffness - Pied Gauche",'stiffness_left'),
            ("Frequency - Pied Droit", 'frequency_right'),
            ("Frequency - Pied Gauche",'frequency_left')
        ]

        for label, key in parameters:
            st.markdown(f"### üìå {label}")
            data = extract_param(index_map[key])
            stats_df = compute_statistics_by_zone(data, label)
            st.dataframe(stats_df)

            st.markdown("‚ÑπÔ∏è **Interpr√©tation des CV :**")
            st.markdown("- ‚úÖ **CV < 10%** : faible variabilit√©, la moyenne est repr√©sentative")
            st.markdown("- ‚ö†Ô∏è **CV entre 10% et 20%** : variabilit√© mod√©r√©e, interpr√©tation avec prudence")
            st.markdown("- ‚ùå **CV > 20%** : forte variabilit√©, la moyenne est peu fiable")


    # --- Partie 2 : Test de normalit√© de Shapiro-Wilk ---       
    elif page == "Test de normalit√©":
        st.header("üß™ Normalit√© par zone, param√®tre et c√¥t√© :(Shapiro-Wilk)")

        st.markdown("""
        **Objectif :** V√©rifier si les donn√©es suivent une distribution normale dans chaque zone.
        """)

        def test_normality_only(data, param_name, foot_zones):
            results = []
            for i, zone in enumerate(foot_zones):
                values = pd.to_numeric(data.iloc[:, i], errors='coerce').dropna()

                if len(values) >= 3:
                    stat, p_value = shapiro(values)
                else:
                    stat, p_value = np.nan, np.nan

                results.append({
                    "Zone": zone,
                    "p-value": p_value,
                    "Conclusion": "‚úÖ Normale" if pd.notna(p_value) and p_value > 0.05 else "‚ùå Non normale"
                })

            result_df = pd.DataFrame(results)
            st.write(f"üìã R√©sultats du test de Shapiro-Wilk pour : {param_name}")
            st.dataframe(result_df)


        def test_symmetry_with_normality(key_right, key_left, param_name, foot_zones):
            data_right = extract_param(index_map[key_right])
            data_left = extract_param(index_map[key_left])

            results = []
            for i, zone in enumerate(foot_zones):
                vals_right = pd.to_numeric(data_right.iloc[:, i], errors='coerce').dropna()
                vals_left = pd.to_numeric(data_left.iloc[:, i], errors='coerce').dropna()

                # Indices communs pour test appari√©
                common_idx = vals_right.index.intersection(vals_left.index)
                vals_right = vals_right.loc[common_idx]
                vals_left = vals_left.loc[common_idx]

                # Test normalit√©
                norm_right = len(vals_right) >= 3 and shapiro(vals_right).pvalue > 0.05
                norm_left = len(vals_left) >= 3 and shapiro(vals_left).pvalue > 0.05

                if norm_right and norm_left:
                    stat, p_value = ttest_rel(vals_right, vals_left)
                    test_used = "Test t appari√©"
                else:
                    try:
                        stat, p_value = wilcoxon(vals_right, vals_left)
                        test_used = "Test de Wilcoxon"
                    except ValueError:
                        stat, p_value = np.nan, np.nan
                        test_used = "Test de Wilcoxon (impossible)"

                results.append({
                    "Zone": zone,
                    "Test utilis√©": test_used,
                    "Statistique": stat,
                    "p-value": p_value,
                    "Conclusion": "‚ùå Diff√©rence significative" if pd.notna(p_value) and p_value < 0.05 else "‚úÖ Pas de diff√©rence significative"
                })

            df_results = pd.DataFrame(results)
            st.write(f"üìã R√©sultats des tests entre pied droit et gauche pour : {param_name}")
            st.dataframe(df_results)


        # Affichage normalit√© simple
        for label, key in parameters:
            st.markdown(f"### üîç {label}")
            data = extract_param(index_map[key])
            test_normality_only(data, label, foot_zones)

        # Test de comparaison sym√©trie avec test t ou Wilcoxon selon normalit√©
        for param_name, key_right, key_left in [
            ("Tone", "tone_right", "tone_left"),
            ("Stiffness", "stiffness_right", "stiffness_left"),
            ("Frequency", "frequency_right", "frequency_left")
        ]:
            test_symmetry_with_normality(key_right, key_left, param_name, foot_zones)


        st.markdown("""
        ### üß† Interpr√©tation
        Ce tableau affiche la normalit√© **pour chaque combinaison : zone du pied √ó param√®tre √ó c√¥t√©**.

        - ‚úÖ signifie que les donn√©es suivent une distribution normale (*tests param√©triques possibles*)
        - ‚ùå signifie que les donn√©es ne sont pas normales (*tests non param√©triques recommand√©s*)

        Le **test de Shapiro-Wilk** permet de v√©rifier si les donn√©es suivent une **loi normale**.  
        - Si la *p-value > 0.05*, on consid√®re que les donn√©es sont **normalement distribu√©es** (*test param√©trique possible* : t-test, ANOVA).  
        - Si la *p-value ‚â§ 0.05*, les donn√©es **ne suivent pas une loi normale** (*test non param√©trique recommand√©* : Wilcoxon, Friedman).

        Pour comparer pied droit vs pied gauche,  
        - On effectue un test t appari√© si les deux c√¥t√©s ont une distribution normale (Shapiro-Wilk p>0.05).  
        - Sinon on fait un test de Wilcoxon appari√© (non param√©trique).  
        """)

    
    elif page == "plot_left_right_comparison":
        st.header("üìä Comparaison Gauche vs Droit ‚Äì par Param√®tre et Zone")

        def plot_left_right_comparison(param_key_right, param_key_left, param_name, foot_zones, df, index_map):
            data_right = extract_param(index_map[param_key_right])
            data_left = extract_param(index_map[param_key_left])

            for i, zone in enumerate(foot_zones):

                vals_right = pd.to_numeric(data_right.iloc[:, i], errors='coerce').dropna()
                vals_left = pd.to_numeric(data_left.iloc[:, i], errors='coerce').dropna()

                # Q-Q Plots
                fig, axs = plt.subplots(1, 2, figsize=(12, 5))
                fig.suptitle(f"{param_name} ‚Äì Zone : {zone}", fontsize=16)

                probplot(vals_right, dist="norm", plot=axs[0])
                axs[0].set_title("Q-Q Plot Pied Droit")
                axs[0].grid(True)

                probplot(vals_left, dist="norm", plot=axs[1])
                axs[1].set_title("Q-Q Plot Pied Gauche")
                axs[1].grid(True)

                st.pyplot(fig)

                fig2, ax2 = plt.subplots(figsize=(6, 4))
                bp_right = ax2.boxplot(vals_right, positions=[1], widths=0.6, patch_artist=True,
                                    boxprops=dict(facecolor="lightblue"))
                bp_left = ax2.boxplot(vals_left, positions=[2], widths=0.6, patch_artist=True,
                                    boxprops=dict(facecolor="lightgreen"))

                ax2.set_xticks([1, 2])
                ax2.set_xticklabels(["Pied Droit", "Pied Gauche"])
                ax2.set_title(f"Boxplot comparatif ‚Äì {param_name} ‚Äì {zone}")
                ax2.grid(True)
                st.pyplot(fig2)

        for param_name, key_right, key_left in [
            ("Tone", 'tone_right', 'tone_left'),
            ("Stiffness", 'stiffness_right', 'stiffness_left'),
            ("Frequency", 'frequency_right', 'frequency_left')
        ]:
            st.subheader(f"üîπ {param_name}")
            plot_left_right_comparison(key_right, key_left, param_name, foot_zones, df, index_map)

        
    elif page == "plot planck_hartmann":
        st.header("üé≠ Planck-Hartmann")
        foot_zones = ['Hallux', '1T', '2-3T', '5T', 'Voute int', 'Voute ext', 'Talon']
        def plot_planck_hartmann(right_df, left_df, param_name):
            right_numeric = right_df.apply(pd.to_numeric, errors='coerce')
            left_numeric = left_df.apply(pd.to_numeric, errors='coerce')

            # Centrer les donn√©es par zone (diff√©rence √† la moyenne par zone)
            centered_right = right_numeric - right_numeric.mean()
            centered_left = left_numeric - left_numeric.mean()

            # Calcul moyenne g√©n√©rale (droite + gauche)
            mean_global = pd.concat([right_numeric, left_numeric]).mean()

            fig, ax = plt.subplots(figsize=(14, 6))
            x = np.arange(len(foot_zones))
            width = 0.3

            # Tracer chaque individu (droite)
            for i in range(len(centered_right)):
                ax.plot(x - width/2, centered_right.iloc[i], marker='o', linestyle='-', color='blue', alpha=0.6, label="Individu Pied Droit" if i == 0 else "")

            # Tracer chaque individu (gauche)
            for i in range(len(centered_left)):
                ax.plot(x + width/2, centered_left.iloc[i], marker='o', linestyle='--', color='orange', alpha=0.6, label="Individu Pied Gauche" if i == 0 else "")

            # Tracer la moyenne g√©n√©rale (droite + gauche) centr√©e (ligne √©paisse et couleur distincte)
            mean_centered = mean_global - mean_global.mean()
            ax.plot(x, mean_centered, marker='s', linestyle='-', color='green', linewidth=3, label="Moyenne G√©n√©rale", alpha=0.8)

            # Ligne horizontale 0
            ax.axhline(0, color='red', linestyle='--', label="Moyenne zone = 0")

            ax.set_xticks(x)
            ax.set_xticklabels(foot_zones, fontsize=12)
            ax.set_ylabel("Valeur centr√©e (diff√©rence √† la moyenne)")
            ax.set_title(f"Param√®tre : {param_name.upper()} (centr√© par zone)")
            ax.legend(loc='upper right')
            ax.grid(True)
            
            # --- Partie t√©l√©chargement ---
            buf = io.BytesIO()
            fig.savefig(buf, format="png")
            buf.seek(0)
            st.download_button(
                label="üì• T√©l√©charger le graphique (PNG)",
                data=buf,
                file_name=f"Planck_Hartmann_{param_name}.png",
                mime="image/png"
            )

            st.pyplot(fig)

            # Calcul IC 95% global par c√¥t√© (moyenne des std divis√©e par racine n)
            ci_right = 1.96 * right_numeric.std().mean() / np.sqrt(len(right_numeric))
            ci_left = 1.96 * left_numeric.std().mean() / np.sqrt(len(left_numeric))
            st.info(f"Intervalle de confiance 95% estim√© : Pied droit ¬±{ci_right:.2f}, Pied gauche ¬±{ci_left:.2f}")

        # --- Simulation donn√©es (√† remplacer par tes extractions r√©elles) ---
        np.random.seed(42)
        n_subjects = 15

        # G√©n√©rer donn√©es factices pour chaque param√®tre, 15 sujets, 7 zones
        df_tone_right = pd.DataFrame(np.random.normal(50, 10, (n_subjects, 7)), columns=foot_zones)
        df_tone_left = pd.DataFrame(np.random.normal(48, 9, (n_subjects, 7)), columns=foot_zones)

        df_stiffness_right = pd.DataFrame(np.random.normal(30, 5, (n_subjects, 7)), columns=foot_zones)
        df_stiffness_left = pd.DataFrame(np.random.normal(32, 4, (n_subjects, 7)), columns=foot_zones)

        df_frequency_right = pd.DataFrame(np.random.normal(20, 3, (n_subjects, 7)), columns=foot_zones)
        df_frequency_left = pd.DataFrame(np.random.normal(18, 3, (n_subjects, 7)), columns=foot_zones)

        # Affichage
        st.header("üé≠ Planck-Hartmann - Comparaison Pied Droit / Pied Gauche")

        plot_planck_hartmann(df_tone_right, df_tone_left, "Tone")
        plot_planck_hartmann(df_stiffness_right, df_stiffness_left, "Stiffness")
        plot_planck_hartmann(df_frequency_right, df_frequency_left, "Frequency")
        

        
        # --- Interpr√©tation du Plot Planck-Hartmann ---
        st.markdown("### üß† Interpr√©tation des graphiques Planck-Hartmann")
        st.markdown("""
        - **Les courbes bleues** repr√©sentent les valeurs centr√©es pour chaque individu au pied droit,  
        tandis que les **courbes orange** repr√©sentent celles pour le pied gauche.  
        - Les valeurs sont centr√©es par zone, c‚Äôest-√†-dire que l‚Äôon montre l‚Äô√©cart √† la moyenne de chaque zone,  
        ce qui permet de visualiser les diff√©rences relatives de chaque sujet selon la zone du pied.

        - La **courbe verte √©paisse** correspond √† la moyenne g√©n√©rale (droite + gauche) de tous les sujets,  
        permettant d‚Äô√©valuer la tendance moyenne globale pour chaque zone.

        - La **ligne rouge en pointill√©** indique la r√©f√©rence z√©ro (moyenne par zone).  
        Des points au-dessus indiquent des valeurs sup√©rieures √† la moyenne,  
        en dessous des valeurs inf√©rieures.

        - Les intervalles de confiance 95% (affich√©s en info) donnent une id√©e de la variabilit√© et de la pr√©cision de la moyenne.

        ### Comment interpr√©ter ?

        - Si les courbes individuelles (bleues et oranges) sont proches de la moyenne verte, cela signifie une homog√©n√©it√© des profils entre sujets.  
        - De fortes variations individuelles peuvent indiquer une variabilit√© importante √† prendre en compte.  
        - Des diff√©rences syst√©matiques entre pied droit et gauche (d√©calage entre les courbes bleues et oranges) peuvent r√©v√©ler des asym√©tries biom√©caniques ou fonctionnelles.

        Cette visualisation permet ainsi d‚Äôidentifier facilement les zones du pied o√π la variabilit√© ou les asym√©tries sont les plus marqu√©es, et de guider des analyses ou interventions cibl√©es.
        """)

    elif page == "Moyenne r√©p√©titions":
        st.header("üìä Analyse avec moyenne des r√©p√©titions par zone, pied droit et pied gauche")

        def plot_planck_hartmann_mean_repetitions(right_df, left_df, param_name, foot_zones):
            st.markdown(f"### üé≠ Planck-Hartmann : {param_name.upper()}")

            right_numeric = right_df.apply(pd.to_numeric, errors='coerce')
            left_numeric = left_df.apply(pd.to_numeric, errors='coerce')

            # Moyenne des r√©p√©titions par zone (axe=0 = colonne)
            mean_right = right_numeric.mean(axis=0)
            mean_left = left_numeric.mean(axis=0)

            # Centrer chaque r√©p√©tition par rapport √† sa moyenne zone
            centered_right = right_numeric.subtract(mean_right, axis=1)
            centered_left = left_numeric.subtract(mean_left, axis=1)

            # Moyenne globale (droite + gauche)
            mean_global = pd.concat([right_numeric, left_numeric]).mean(axis=0)
            mean_global_centered = mean_global - mean_global.mean()

            fig, ax = plt.subplots(figsize=(14, 6))
            x = np.arange(len(foot_zones))
            width = 0.3

            # Tracer r√©p√©titions pied droit
            for i in range(len(centered_right)):
                ax.plot(x - width/2, centered_right.iloc[i], marker='o', linestyle='-', color='blue', alpha=0.6, label="R√©p√©tition Pied Droit" if i == 0 else "")

            # Tracer r√©p√©titions pied gauche
            for i in range(len(centered_left)):
                ax.plot(x + width/2, centered_left.iloc[i], marker='o', linestyle='--', color='orange', alpha=0.6, label="R√©p√©tition Pied Gauche" if i == 0 else "")

            # Tracer moyenne globale
            ax.plot(x, mean_global_centered, marker='s', linestyle='-', color='green', linewidth=3, label="Moyenne G√©n√©rale", alpha=0.8)

            ax.axhline(0, color='red', linestyle='--', label="Moyenne zone = 0")
            ax.set_xticks(x)
            ax.set_xticklabels(foot_zones)
            ax.set_ylabel("Valeur centr√©e (diff√©rence √† la moyenne)")
            ax.set_title(f"Param√®tre : {param_name.upper()} (centr√© par zone)")
            ax.legend(loc='upper right')
            ax.grid(True)
            
            # --- Partie t√©l√©chargement ---
            buf = io.BytesIO()
            fig.savefig(buf, format="png")
            buf.seek(0)
            st.download_button(
                label="üì• T√©l√©charger le graphique (PNG)",
                data=buf,
                file_name=f"Planck_Hartmann_{param_name}.png",
                mime="image/png"
            )

            st.pyplot(fig)

            ci_right = 1.96 * right_numeric.std().mean() / np.sqrt(len(right_numeric))
            ci_left = 1.96 * left_numeric.std().mean() / np.sqrt(len(left_numeric))
            st.info(f"Intervalle de confiance 95% estim√© : Pied droit ¬±{ci_right:.2f}, Pied gauche ¬±{ci_left:.2f}")

        # Liste des param√®tres √† analyser et afficher
        parameters = [
            ("Tone", "tone_right", "tone_left"),
            ("Stiffness", "stiffness_right", "stiffness_left"),
            ("Frequency", "frequency_right", "frequency_left")
        ]

        for param_name, key_right, key_left in parameters:
            st.markdown(f"## Analyse du param√®tre : {param_name}")
            data_right = extract_param(index_map[key_right])
            data_left = extract_param(index_map[key_left])
            plot_planck_hartmann_mean_repetitions(data_right, data_left, param_name, foot_zones)


    elif page == "test_symmetry_with_parametric_choice":       
        def test_symmetry_with_parametric_choice(param_key_right, param_key_left, foot_zones):
            data_right = extract_param(index_map[param_key_right])
            data_left = extract_param(index_map[param_key_left])

            results = []

            for i, zone in enumerate(foot_zones):
                vals_right = pd.to_numeric(data_right.iloc[:, i], errors='coerce').dropna()
                vals_left = pd.to_numeric(data_left.iloc[:, i], errors='coerce').dropna()

                # Indices communs pour test appari√©
                common_idx = vals_right.index.intersection(vals_left.index)
                vals_right = vals_right.loc[common_idx]
                vals_left = vals_left.loc[common_idx]

                # V√©rification normalit√© avec Shapiro-Wilk (min 3 donn√©es)
                norm_right = len(vals_right) >= 3 and shapiro(vals_right).pvalue > 0.05
                norm_left = len(vals_left) >= 3 and shapiro(vals_left).pvalue > 0.05

                # Choix du test selon normalit√©
                if norm_right and norm_left:
                    stat, p_value = ttest_rel(vals_right, vals_left)
                    test_used = "Test t appari√© (param√©trique)"
                else:
                    try:
                        stat, p_value = wilcoxon(vals_right, vals_left)
                        test_used = "Test de Wilcoxon (non param√©trique)"
                    except ValueError:
                        stat, p_value = np.nan, np.nan
                        test_used = "Test de Wilcoxon (impossible)"

                # Interpr√©tation du r√©sultat
                if pd.isna(p_value):
                    conclusion = "‚ö†Ô∏è Donn√©es insuffisantes"
                elif p_value < 0.05:
                    conclusion = "‚ùå Diff√©rence significative"
                else:
                    conclusion = "‚úÖ Pas de diff√©rence significative"

                results.append({
                    "Zone": zone,
                    "Test utilis√©": test_used,
                    "Statistique": round(stat, 4) if not pd.isna(stat) else np.nan,
                    "p-value": round(p_value, 4) if not pd.isna(p_value) else np.nan,
                    "Conclusion": conclusion
                })

            return pd.DataFrame(results)

        # --- Int√©gration dans Streamlit ---

        page = st.sidebar.radio("Choisir la page :", ["Test de sym√©trie Gauche/Droite", "Autres pages..."])

        if uploaded_file:  # Ton code d'import des donn√©es

            if page == "Test de sym√©trie Gauche/Droite":
                st.header("‚öñÔ∏è Test de sym√©trie Gauche vs Droit (t-test ou Wilcoxon selon normalit√©)")

                for param_name, key_right, key_left in [
                    ("Tone", "tone_right", "tone_left"),
                    ("Stiffness", "stiffness_right", "stiffness_left"),
                    ("Frequency", "frequency_right", "frequency_left")
                ]:
                    st.subheader(f"üîπ {param_name}")
                    df_results = test_symmetry_with_parametric_choice(key_right, key_left, foot_zones)
                    st.dataframe(df_results)

                st.markdown("""
                **Interpr√©tation :**  
                - Si **p-value < 0.05**, il existe une diff√©rence significative entre pied droit et gauche pour cette zone et param√®tre.  
                - Si **p-value ‚â• 0.05**, pas de diff√©rence significative (sym√©trie).  
                - Le test utilis√© est choisi selon la normalit√© des donn√©es (test de Shapiro-Wilk) :  
                - Test t appari√© si donn√©es normales (param√©trique)  
                - Test de Wilcoxon appari√© sinon (non param√©trique)
                """)


    elif page == "Test inter-zone (param√©trique/non-param√©trique)": # Consolidated and renamed page
        st.header("üß™ Comparaison inter-zones (ANOVA RM / Friedman)")

        # Simplified function for the main page display
        def test_inter_zone_summary(param_key, param_name, foot_zones):
            data = extract_param(index_map[param_key])
            # Ensure data is numeric and drop NaNs for analysis. Important for 'per subject' analysis later.
            data_num = data.apply(pd.to_numeric, errors='coerce').dropna()

            if data_num.empty:
                st.warning(f"Pas assez de donn√©es compl√®tes pour analyser {param_name}.")
                return

            # Test de normalit√© sur chaque zone
            normalities = []
            for col in data_num.columns: # Iterate over the actual columns of the cleaned data_num
                vals = data_num[col].dropna()
                if len(vals) >= 3:
                    p_val = shapiro(vals).pvalue
                else:
                    p_val = np.nan
                normalities.append(p_val)

            all_normal = all([(p > 0.05) for p in normalities if not pd.isna(p)])

            st.write(f"### R√©sultats pour : {param_name}")
            norm_df = pd.DataFrame({
                "Zone": foot_zones, # Use global foot_zones for display, assuming data_num columns map to it
                "p-value normalit√©": [f"{p:.4f}" if not pd.isna(p) else "N/A" for p in normalities],
                "Distribution": ["Normale" if (p > 0.05) else "Non normale" if not pd.isna(p) else "N/A" for p in normalities]
            })
            st.dataframe(norm_df)

            # Prepare data for ANOVA RM or Friedman: long format for AnovaRM, list of arrays for Friedman
            df_long = data_num.reset_index().melt(id_vars='index', value_vars=data_num.columns,
                                                     var_name='Zone', value_name='Valeur')
            df_long = df_long.rename(columns={'index': 'Sujet'})

            if all_normal:
                st.write("‚úÖ Toutes les zones consid√©r√©es comme normales. Effectue une ANOVA √† mesures r√©p√©t√©es.")
                try:
                    # Ensure 'Sujet' and 'Zone' are strings as AnovaRM expects
                    df_long['Sujet'] = df_long['Sujet'].astype(str)
                    df_long['Zone'] = df_long['Zone'].astype(str)
                    aovrm = AnovaRM(df_long, 'Valeur', 'Sujet', within=['Zone'])
                    res = aovrm.fit()
                    st.text(res.summary().as_text()) # Use as_text() for better display in Streamlit
                    p_val = res.anova_table["Pr > F"][0]

                    if p_val < 0.05:
                        st.success(f"Diff√©rence significative entre les zones (p = {p_val:.4f})")
                    else:
                        st.info(f"Aucune diff√©rence significative d√©tect√©e entre les zones (p = {p_val:.4f})")
                except Exception as e:
                    st.error(f"Erreur lors de l'ANOVA √† mesures r√©p√©t√©es : {e}")
                    st.warning("Assurez-vous que chaque sujet a des donn√©es pour toutes les zones pour l'ANOVA RM.")
            else:
                st.write("‚ùå Au moins une zone ne suit pas une distribution normale. Effectue un test de Friedman.")
                # Friedman takes *args, each arg is a data array for a group/zone
                vals_for_friedman = [data_num[col].dropna().values for col in data_num.columns]
                # Friedman requires at least 3 groups, and each group needs valid data
                if len(vals_for_friedman) < 3 or any(len(v) == 0 for v in vals_for_friedman):
                    st.warning("Pas assez de groupes ou de donn√©es valides par groupe pour le test de Friedman.")
                else:
                    try:
                        stat, p_val = friedmanchisquare(*vals_for_friedman)
                        st.write(f"Statistique Friedman : {stat:.4f}")
                        if p_val < 0.05:
                            st.success(f"Diff√©rence significative entre les zones (p = {p_val:.4f})")
                        else:
                            st.info(f"Aucune diff√©rence significative d√©tect√©e entre les zones (p = {p_val:.4f})")
                    except Exception as e:
                        st.error(f"Erreur lors du test de Friedman : {e}")
                        st.warning("V√©rifiez que toutes les zones ont des observations appari√©es (m√™me nombre de sujets avec des donn√©es compl√®tes pour toutes les zones).")

        # Loop through parameters (Tone, Stiffness, Frequency) for both right and left feet
        for param_name, key_right, key_left in parameters_comparison_keys: # Use comparison keys as they hold (param_name, right_key, left_key)
            st.markdown(f"## Analyse des zones pour {param_name}")
            st.subheader(f"Pied Droit - {param_name}")
            test_inter_zone_summary(key_right, f"{param_name} (Droit)", foot_zones) # Pass param_name with side
            st.subheader(f"Pied Gauche - {param_name}")
            test_inter_zone_summary(key_left, f"{param_name} (Gauche)", foot_zones) # Pass param_name with side

            st.markdown("---")
            st.markdown("### üß† Interpr√©tation des tests statistiques inter-zones")

            st.markdown("""
            - **But de ces tests** : d√©terminer si les diff√©rentes **zones du pied** pr√©sentent des **valeurs significativement diff√©rentes** pour un param√®tre donn√© (tone, stiffness, frequency, etc.).

            #### üî¨ ANOVA √† mesures r√©p√©t√©es (test param√©trique)
            - Utilis√© lorsque **toutes les zones ont une distribution normale** (test de Shapiro-Wilk p > 0.05).
            - Ce test compare les moyennes entre les zones, en tenant compte des mesures r√©p√©t√©es sur les m√™mes sujets.
            - **Interpr√©tation :**
            - Si *p-value < 0.05* ‚Üí **diff√©rences significatives** entre au moins deux zones.
            - Si *p-value ‚â• 0.05* ‚Üí **pas de diff√©rence significative**, le param√®tre est distribu√© de fa√ßon homog√®ne entre les zones.

            #### üß™ Test de Friedman (test non param√©trique)
            - Utilis√© quand **au moins une zone n‚Äôa pas une distribution normale**.
            - C‚Äôest l‚Äôalternative non param√©trique √† l‚ÄôANOVA pour donn√©es appari√©es.
            - **Interpr√©tation :**
            - Si *p-value < 0.05* ‚Üí **diff√©rences significatives** entre les zones.
            - Si *p-value ‚â• 0.05* ‚Üí **pas de diff√©rence significative**.

            üëâ Ces tests permettent de d√©tecter des **asym√©tries fonctionnelles ou structurelles** dans le pied.
            """)



    else:
        st.info("Veuillez charger un fichier Excel pour commencer l'analyse.")
